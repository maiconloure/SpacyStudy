{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  spacy\n",
    "nlp = spacy.load(\"pt_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.pt.Portuguese"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Estamos estudando spaCy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Doc object:\n",
      "\n",
      "class Doc(builtins.object)\n",
      " |  A sequence of Token objects. Access sentences and named entities, export\n",
      " |  annotations to numpy arrays, losslessly serialize to compressed binary\n",
      " |  strings. The `Doc` object holds an array of `TokenC` structs. The\n",
      " |  Python-level `Token` and `Span` objects are views of this array, i.e.\n",
      " |  they don't own the data themselves.\n",
      " |  \n",
      " |  EXAMPLE:\n",
      " |      Construction 1\n",
      " |      >>> doc = nlp(u'Some text')\n",
      " |  \n",
      " |      Construction 2\n",
      " |      >>> from spacy.tokens import Doc\n",
      " |      >>> doc = Doc(nlp.vocab, words=[u'hello', u'world', u'!'],\n",
      " |      >>>           spaces=[True, False, False])\n",
      " |  \n",
      " |  DOCS: https://spacy.io/api/doc\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bytes__(...)\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      Get a `Token` or `Span` object.\n",
      " |      \n",
      " |      i (int or tuple) The index of the token, or the slice of the document\n",
      " |          to get.\n",
      " |      RETURNS (Token or Span): The token at `doc[i]]`, or the span at\n",
      " |          `doc[start : end]`.\n",
      " |      \n",
      " |      EXAMPLE:\n",
      " |          >>> doc[i]\n",
      " |          Get the `Token` object at position `i`, where `i` is an integer.\n",
      " |          Negative indexing is supported, and follows the usual Python\n",
      " |          semantics, i.e. `doc[-2]` is `doc[len(doc) - 2]`.\n",
      " |      \n",
      " |          >>> doc[start : end]]\n",
      " |          Get a `Span` object, starting at position `start` and ending at\n",
      " |          position `end`, where `start` and `end` are token indices. For\n",
      " |          instance, `doc[2:5]` produces a span consisting of tokens 2, 3 and\n",
      " |          4. Stepped slices (e.g. `doc[start : end : step]`) are not\n",
      " |          supported, as `Span` objects must be contiguous (cannot have gaps).\n",
      " |          You can use negative indices and open-ended ranges, which have\n",
      " |          their normal Python semantics.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#getitem\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      Create a Doc object.\n",
      " |      \n",
      " |      vocab (Vocab): A vocabulary object, which must match any models you\n",
      " |          want to use (e.g. tokenizer, parser, entity recognizer).\n",
      " |      words (list or None): A list of unicode strings to add to the document\n",
      " |          as words. If `None`, defaults to empty list.\n",
      " |      spaces (list or None): A list of boolean values, of the same length as\n",
      " |          words. True means that the word is followed by a space, False means\n",
      " |          it is not. If `None`, defaults to `[True]*len(words)`\n",
      " |      user_data (dict or None): Optional extra data to attach to the Doc.\n",
      " |      RETURNS (Doc): The newly constructed object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#init\n",
      " |  \n",
      " |  __iter__(...)\n",
      " |      Iterate over `Token`  objects, from which the annotations can be\n",
      " |      easily accessed. This is the main way of accessing `Token` objects,\n",
      " |      which are the main way annotations are accessed from Python. If faster-\n",
      " |      than-Python speeds are required, you can instead access the annotations\n",
      " |      as a numpy array, or access the underlying C data directly from Cython.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#iter\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      The number of tokens in the document.\n",
      " |      \n",
      " |      RETURNS (int): The number of tokens in the document.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#len\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __unicode__(...)\n",
      " |  \n",
      " |  char_span(...)\n",
      " |      Create a `Span` object from the slice\n",
      " |      `doc.text[start_idx : end_idx]`. Returns None if no valid `Span` can be\n",
      " |      created.\n",
      " |      \n",
      " |      doc (Doc): The parent document.\n",
      " |      start_idx (int): The index of the first character of the span.\n",
      " |      end_idx (int): The index of the first character after the span.\n",
      " |      label (uint64 or string): A label to attach to the Span, e.g. for\n",
      " |          named entities.\n",
      " |      kb_id (uint64 or string):  An ID from a KB to capture the meaning of a\n",
      " |          named entity.\n",
      " |      vector (ndarray[ndim=1, dtype='float32']): A meaning representation of\n",
      " |          the span.\n",
      " |      alignment_mode (str): How character indices are aligned to token\n",
      " |          boundaries. Options: \"strict\" (character indices must be aligned\n",
      " |          with token boundaries), \"contract\" (span of all tokens completely\n",
      " |          within the character span), \"expand\" (span of all tokens at least\n",
      " |          partially covered by the character span). Defaults to \"strict\".\n",
      " |      RETURNS (Span): The newly constructed object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#char_span\n",
      " |  \n",
      " |  count_by(...)\n",
      " |      Count the frequencies of a given attribute. Produces a dict of\n",
      " |      `{attribute (int): count (ints)}` frequencies, keyed by the values of\n",
      " |      the given attribute ID.\n",
      " |      \n",
      " |      attr_id (int): The attribute ID to key the counts.\n",
      " |      RETURNS (dict): A dictionary mapping attributes to integer counts.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#count_by\n",
      " |  \n",
      " |  extend_tensor(...)\n",
      " |      Concatenate a new tensor onto the doc.tensor object.\n",
      " |      \n",
      " |      The doc.tensor attribute holds dense feature vectors\n",
      " |      computed by the models in the pipeline. Let's say a\n",
      " |      document with 30 words has a tensor with 128 dimensions\n",
      " |      per word. doc.tensor.shape will be (30, 128). After\n",
      " |      calling doc.extend_tensor with an array of shape (30, 64),\n",
      " |      doc.tensor == (30, 192).\n",
      " |  \n",
      " |  from_array(...)\n",
      " |      Load attributes from a numpy array. Write to a `Doc` object, from an\n",
      " |      `(M, N)` array of attributes.\n",
      " |      \n",
      " |      attrs (list) A list of attribute ID ints.\n",
      " |      array (numpy.ndarray[ndim=2, dtype='int32']): The attribute values.\n",
      " |      RETURNS (Doc): Itself.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#from_array\n",
      " |  \n",
      " |  from_bytes(...)\n",
      " |      Deserialize, i.e. import the document contents from a binary string.\n",
      " |      \n",
      " |      data (bytes): The string to load from.\n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      RETURNS (Doc): Itself.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#from_bytes\n",
      " |  \n",
      " |  from_disk(...)\n",
      " |      Loads state from a directory. Modifies the object in place and\n",
      " |      returns it.\n",
      " |      \n",
      " |      path (unicode or Path): A path to a directory. Paths may be either\n",
      " |          strings or `Path`-like objects.\n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      RETURNS (Doc): The modified `Doc` object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#from_disk\n",
      " |  \n",
      " |  get_lca_matrix(...)\n",
      " |      Calculates a matrix of Lowest Common Ancestors (LCA) for a given\n",
      " |      `Doc`, where LCA[i, j] is the index of the lowest common ancestor among\n",
      " |      token i and j.\n",
      " |      \n",
      " |      RETURNS (np.array[ndim=2, dtype=numpy.int32]): LCA matrix with shape\n",
      " |          (n, n), where n = len(self).\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#get_lca_matrix\n",
      " |  \n",
      " |  merge(...)\n",
      " |      Retokenize the document, such that the span at\n",
      " |      `doc.text[start_idx : end_idx]` is merged into a single token. If\n",
      " |      `start_idx` and `end_idx `do not mark start and end token boundaries,\n",
      " |      the document remains unchanged.\n",
      " |      \n",
      " |      start_idx (int): Character index of the start of the slice to merge.\n",
      " |      end_idx (int): Character index after the end of the slice to merge.\n",
      " |      **attributes: Attributes to assign to the merged token. By default,\n",
      " |          attributes are inherited from the syntactic root of the span.\n",
      " |      RETURNS (Token): The newly merged token, or `None` if the start and end\n",
      " |          indices did not fall at token boundaries.\n",
      " |  \n",
      " |  print_tree(...)\n",
      " |  \n",
      " |  retokenize(...)\n",
      " |      Context manager to handle retokenization of the Doc.\n",
      " |      Modifications to the Doc's tokenization are stored, and then\n",
      " |      made all at once when the context manager exits. This is\n",
      " |      much more efficient, and less error-prone.\n",
      " |      \n",
      " |      All views of the Doc (Span and Token) created before the\n",
      " |      retokenization are invalidated, although they may accidentally\n",
      " |      continue to work.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#retokenize\n",
      " |      USAGE: https://spacy.io/usage/linguistic-features#retokenization\n",
      " |  \n",
      " |  similarity(...)\n",
      " |      Make a semantic similarity estimate. The default estimate is cosine\n",
      " |      similarity using an average of word vectors.\n",
      " |      \n",
      " |      other (object): The object to compare with. By default, accepts `Doc`,\n",
      " |          `Span`, `Token` and `Lexeme` objects.\n",
      " |      RETURNS (float): A scalar similarity score. Higher is more similar.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#similarity\n",
      " |  \n",
      " |  to_array(...)\n",
      " |      Export given token attributes to a numpy `ndarray`.\n",
      " |      If `attr_ids` is a sequence of M attributes, the output array will be\n",
      " |      of shape `(N, M)`, where N is the length of the `Doc` (in tokens). If\n",
      " |      `attr_ids` is a single attribute, the output shape will be (N,). You\n",
      " |      can specify attributes by integer ID (e.g. spacy.attrs.LEMMA) or\n",
      " |      string name (e.g. 'LEMMA' or 'lemma').\n",
      " |      \n",
      " |      attr_ids (list[]): A list of attributes (int IDs or string names).\n",
      " |      RETURNS (numpy.ndarray[long, ndim=2]): A feature matrix, with one row\n",
      " |          per word, and one column per attribute indicated in the input\n",
      " |          `attr_ids`.\n",
      " |      \n",
      " |      EXAMPLE:\n",
      " |          >>> from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n",
      " |          >>> doc = nlp(text)\n",
      " |          >>> # All strings mapped to integers, for easy export to numpy\n",
      " |          >>> np_array = doc.to_array([LOWER, POS, ENT_TYPE, IS_ALPHA])\n",
      " |  \n",
      " |  to_bytes(...)\n",
      " |      Serialize, i.e. export the document contents to a binary string.\n",
      " |      \n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      RETURNS (bytes): A losslessly serialized copy of the `Doc`, including\n",
      " |          all annotations.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#to_bytes\n",
      " |  \n",
      " |  to_disk(...)\n",
      " |      Save the current state to a directory.\n",
      " |      \n",
      " |      path (unicode or Path): A path to a directory, which will be created if\n",
      " |          it doesn't exist. Paths may be either strings or Path-like objects.\n",
      " |      exclude (list): String names of serialization fields to exclude.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#to_disk\n",
      " |  \n",
      " |  to_json(...)\n",
      " |      Convert a Doc to JSON. The format it produces will be the new format\n",
      " |      for the `spacy train` command (not implemented yet).\n",
      " |      \n",
      " |      underscore (list): Optional list of string names of custom doc._.\n",
      " |      attributes. Attribute values need to be JSON-serializable. Values will\n",
      " |      be added to an \"_\" key in the data, e.g. \"_\": {\"foo\": \"bar\"}.\n",
      " |      RETURNS (dict): The data in spaCy's JSON format.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#to_json\n",
      " |  \n",
      " |  to_utf8_array(...)\n",
      " |      Encode word strings to utf8, and export to a fixed-width array\n",
      " |      of characters. Characters are placed into the array in the order:\n",
      " |          0, -1, 1, -2, etc\n",
      " |      For example, if the array is sliced array[:, :8], the array will\n",
      " |      contain the first 4 characters and last 4 characters of each word ---\n",
      " |      with the middle characters clipped out. The value 255 is used as a pad\n",
      " |      value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  get_extension(...) from builtins.type\n",
      " |      Look up a previously registered extension by name.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#get_extension\n",
      " |  \n",
      " |  has_extension(...) from builtins.type\n",
      " |      Check whether an extension has been registered.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (bool): Whether the extension has been registered.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#has_extension\n",
      " |  \n",
      " |  remove_extension(...) from builtins.type\n",
      " |      Remove a previously registered extension.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple of the\n",
      " |          removed extension.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#remove_extension\n",
      " |  \n",
      " |  set_extension(...) from builtins.type\n",
      " |      Define a custom attribute which becomes available as `Doc._`.\n",
      " |      \n",
      " |      name (unicode): Name of the attribute to set.\n",
      " |      default: Optional default value of the attribute.\n",
      " |      getter (callable): Optional getter function.\n",
      " |      setter (callable): Optional setter function.\n",
      " |      method (callable): Optional method for method extension.\n",
      " |      force (bool): Force overwriting existing attribute.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#set_extension\n",
      " |      USAGE: https://spacy.io/usage/processing-pipelines#custom-components-attributes\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  cats\n",
      " |  \n",
      " |  doc\n",
      " |  \n",
      " |  ents\n",
      " |      The named entities in the document. Returns a tuple of named entity\n",
      " |      `Span` objects, if the entity recognizer has been applied.\n",
      " |      \n",
      " |      RETURNS (tuple): Entities in the document, one `Span` per entity.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#ents\n",
      " |  \n",
      " |  has_vector\n",
      " |      A boolean value indicating whether a word vector is associated with\n",
      " |      the object.\n",
      " |      \n",
      " |      RETURNS (bool): Whether a word vector is associated with the object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#has_vector\n",
      " |  \n",
      " |  is_nered\n",
      " |      Check if the document has named entities set. Will return True if\n",
      " |      *any* of the tokens has a named entity tag set (even if the others are\n",
      " |      unknown values), or if the document is empty.\n",
      " |  \n",
      " |  is_parsed\n",
      " |  \n",
      " |  is_sentenced\n",
      " |      Check if the document has sentence boundaries assigned. This is\n",
      " |      defined as having at least one of the following:\n",
      " |      \n",
      " |      a) An entry \"sents\" in doc.user_hooks\";\n",
      " |      b) Doc.is_parsed is set to True;\n",
      " |      c) At least one token other than the first where sent_start is not None.\n",
      " |  \n",
      " |  is_tagged\n",
      " |  \n",
      " |  lang\n",
      " |      RETURNS (uint64): ID of the language of the doc's vocabulary.\n",
      " |  \n",
      " |  lang_\n",
      " |      RETURNS (unicode): Language of the doc's vocabulary, e.g. 'en'.\n",
      " |  \n",
      " |  mem\n",
      " |  \n",
      " |  noun_chunks\n",
      " |      Iterate over the base noun phrases in the document. Yields base\n",
      " |      noun-phrase #[code Span] objects, if the document has been\n",
      " |      syntactically parsed. A base noun phrase, or \"NP chunk\", is a noun\n",
      " |      phrase that does not permit other NPs to be nested within it – so no\n",
      " |      NP-level coordination, no prepositional phrases, and no relative\n",
      " |      clauses.\n",
      " |      \n",
      " |      YIELDS (Span): Noun chunks in the document.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#noun_chunks\n",
      " |  \n",
      " |  noun_chunks_iterator\n",
      " |  \n",
      " |  sentiment\n",
      " |  \n",
      " |  sents\n",
      " |      Iterate over the sentences in the document. Yields sentence `Span`\n",
      " |      objects. Sentence spans have no label. To improve accuracy on informal\n",
      " |      texts, spaCy calculates sentence boundaries from the syntactic\n",
      " |      dependency parse. If the parser is disabled, the `sents` iterator will\n",
      " |      be unavailable.\n",
      " |      \n",
      " |      YIELDS (Span): Sentences in the document.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#sents\n",
      " |  \n",
      " |  tensor\n",
      " |  \n",
      " |  text\n",
      " |      A unicode representation of the document text.\n",
      " |      \n",
      " |      RETURNS (unicode): The original verbatim text of the document.\n",
      " |  \n",
      " |  text_with_ws\n",
      " |      An alias of `Doc.text`, provided for duck-type compatibility with\n",
      " |      `Span` and `Token`.\n",
      " |      \n",
      " |      RETURNS (unicode): The original verbatim text of the document.\n",
      " |  \n",
      " |  user_data\n",
      " |  \n",
      " |  user_hooks\n",
      " |  \n",
      " |  user_span_hooks\n",
      " |  \n",
      " |  user_token_hooks\n",
      " |  \n",
      " |  vector\n",
      " |      A real-valued meaning representation. Defaults to an average of the\n",
      " |      token vectors.\n",
      " |      \n",
      " |      RETURNS (numpy.ndarray[ndim=1, dtype='float32']): A 1D numpy array\n",
      " |          representing the document's semantics.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#vector\n",
      " |  \n",
      " |  vector_norm\n",
      " |      The L2 norm of the document's vector representation.\n",
      " |      \n",
      " |      RETURNS (float): The L2 norm of the vector representation.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/doc#vector_norm\n",
      " |  \n",
      " |  vocab\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos Estamos\n",
      "estudando estudar\n",
      "spaCy spaCy\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Jack foi na padaria comprar pão. Aproveitou e comprei um quilo de carne em Santos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Fui na padaria comprar pão., Aproveitei e comprei um quilo de carne.]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Jack, Santos)\n"
     ]
    }
   ],
   "source": [
    "print(doc.ents)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1013006322a2339181c9f88d62f6a364bb1a779c7164bb035fe320876d0a330"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
